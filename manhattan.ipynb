{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:04:34.437684600Z",
     "start_time": "2023-08-27T14:04:28.183238Z"
    }
   },
   "id": "40f5e12d90480ef"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                      year=\"2012\",\n",
    "                                      image_set=\"train\",\n",
    "                                      transform=data_transform,\n",
    "                                      target_transform=data_transform)\n",
    "\n",
    "test_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                     year=\"2012\",\n",
    "                                     image_set=\"val\",\n",
    "                                     transform=data_transform,\n",
    "                                     target_transform=data_transform)\n",
    "\n",
    "viz_data = datasets.VOCSegmentation(root=\"./data\", year=\"2012\", image_set=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:05:23.265099200Z",
     "start_time": "2023-08-27T14:04:34.439685300Z"
    }
   },
   "id": "13d9279b6c994102"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader: 92 * 16 images\n",
      "test_dataloader: 91 * 16 images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"train_dataloader: {len(train_dataloader)} * {BATCH_SIZE} images\")\n",
    "print(f\"test_dataloader: {len(test_dataloader)} * {BATCH_SIZE} images\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:05:23.270729600Z",
     "start_time": "2023-08-27T14:05:23.267107100Z"
    }
   },
   "id": "43b89a384fa7337a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride, padding, dilation, bias, activation=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride,\n",
    "                              padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = activation\n",
    "        if self.activation:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.activation:\n",
    "            outputs = self.relu(x)\n",
    "        else:\n",
    "            outputs = x\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:06:37.791992700Z",
     "start_time": "2023-08-27T14:06:37.767651700Z"
    }
   },
   "id": "eaebc2b9b79b7719"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "class CustomResNet101(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet101(weights=torchvision.models.ResNet101_Weights.DEFAULT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        auxiliary_x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(auxiliary_x)\n",
    "\n",
    "        return x, auxiliary_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:06:43.194961600Z",
     "start_time": "2023-08-27T14:06:43.165150Z"
    }
   },
   "id": "337f90049382bd35"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "        \n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=int(in_channels/len(pool_sizes)), kernel_size=1)\n",
    "\n",
    "        self.pooling_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(output_size=p), # Pool\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=int(in_channels/len(pool_sizes)), kernel_size=1) # Conv\n",
    "            )\n",
    "            for p in pool_sizes\n",
    "        ]\n",
    "        \n",
    "        ## pool__sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode='bilinear', align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode='bilinear', align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode='bilinear', align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode='bilinear', align_corners=True)\n",
    "\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:16:11.012393700Z",
     "start_time": "2023-08-27T14:16:10.996256200Z"
    }
   },
   "id": "e2319b0d8297d462"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PyramidPoolingModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, pools, in_channels, input_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.pooling_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(output_size=p), # Pool\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=int(in_channels/len(pools)), kernel_size=1) # Conv\n",
    "            ) \n",
    "            for p in pools\n",
    "        ]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = [x]\n",
    "        for pooling_layer in self.pooling_layers:\n",
    "            layer_output = pooling_layer(x)\n",
    "            outputs.append(F.interpolate(layer_output, size=self.input_shape, mode=\"bilinear\", align_corners=True))\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T14:08:26.937359600Z",
     "start_time": "2023-08-27T14:08:26.904557400Z"
    }
   },
   "id": "cb46061ab655b5db"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNorm(\n",
    "            in_channels=4096, out_channels=64, kernel_size=3, stride=1,\n",
    "            padding=1, dilation=1,  bias=False, activation=True)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=64, out_channels=n_classes, kernel_size=1,\n",
    "            stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width),\n",
    "            mode='bilinear', align_corners=True)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T15:01:36.830455Z",
     "start_time": "2023-08-27T15:01:36.802265400Z"
    }
   },
   "id": "2943172d75f7b7e7"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        full_img_size = 256\n",
    "        feature_map_size = 8\n",
    "\n",
    "        self.feature_extractor = CustomResNet101()\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1],height=feature_map_size, width=feature_map_size)\n",
    "        #self.pyramid_pooling = PyramidPoolingModule(input_shape=(8, 8), in_channels=2048, pools = (1, 2, 3, 6))\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=full_img_size, width=full_img_size,\n",
    "            n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs, encoder_auxiliary = self.feature_extractor(x)\n",
    "        pyramid_outputs = self.pyramid_pooling(encoder_outputs)\n",
    "        docoder_outputs = self.decode_feature(pyramid_outputs)\n",
    "        return docoder_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T15:01:41.248991400Z",
     "start_time": "2023-08-27T15:01:41.225377600Z"
    }
   },
   "id": "6e7e950f41abcc56"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 1.8625e-01,  1.8634e-01,  1.8643e-01,  ...,  2.0709e-01,\n            2.1605e-01,  2.2501e-01],\n          [ 1.8610e-01,  1.8629e-01,  1.8647e-01,  ...,  2.2033e-01,\n            2.2973e-01,  2.3913e-01],\n          [ 1.8595e-01,  1.8623e-01,  1.8652e-01,  ...,  2.3357e-01,\n            2.4341e-01,  2.5325e-01],\n          ...,\n          [ 3.0366e-01,  2.9213e-01,  2.8060e-01,  ..., -1.0854e-01,\n           -1.2055e-01, -1.3257e-01],\n          [ 3.0569e-01,  2.9403e-01,  2.8238e-01,  ..., -1.1351e-01,\n           -1.2563e-01, -1.3775e-01],\n          [ 3.0772e-01,  2.9594e-01,  2.8416e-01,  ..., -1.1848e-01,\n           -1.3070e-01, -1.4292e-01]],\n\n         [[-7.4000e-02, -7.0625e-02, -6.7251e-02,  ...,  3.4862e-01,\n            3.5892e-01,  3.6922e-01],\n          [-7.3670e-02, -7.0410e-02, -6.7150e-02,  ...,  3.3603e-01,\n            3.4577e-01,  3.5552e-01],\n          [-7.3340e-02, -7.0195e-02, -6.7049e-02,  ...,  3.2344e-01,\n            3.3263e-01,  3.4181e-01],\n          ...,\n          [-2.5251e-01, -2.5689e-01, -2.6128e-01,  ..., -6.6756e-01,\n           -6.6920e-01, -6.7085e-01],\n          [-2.5034e-01, -2.5496e-01, -2.5958e-01,  ..., -6.8752e-01,\n           -6.8916e-01, -6.9079e-01],\n          [-2.4816e-01, -2.5303e-01, -2.5789e-01,  ..., -7.0749e-01,\n           -7.0911e-01, -7.1073e-01]],\n\n         [[-9.1545e-02, -9.0068e-02, -8.8592e-02,  ...,  1.3597e-01,\n            1.3591e-01,  1.3584e-01],\n          [-8.1670e-02, -8.0312e-02, -7.8954e-02,  ...,  1.4361e-01,\n            1.4383e-01,  1.4406e-01],\n          [-7.1796e-02, -7.0556e-02, -6.9317e-02,  ...,  1.5124e-01,\n            1.5176e-01,  1.5227e-01],\n          ...,\n          [ 4.6400e-02,  4.3095e-02,  3.9790e-02,  ...,  2.4984e-01,\n            2.4252e-01,  2.3521e-01],\n          [ 3.6723e-02,  3.3200e-02,  2.9677e-02,  ...,  2.3592e-01,\n            2.2784e-01,  2.1976e-01],\n          [ 2.7046e-02,  2.3305e-02,  1.9564e-02,  ...,  2.2199e-01,\n            2.1315e-01,  2.0432e-01]],\n\n         ...,\n\n         [[-1.2401e-01, -1.2081e-01, -1.1760e-01,  ...,  5.1910e-03,\n            4.6821e-03,  4.1733e-03],\n          [-1.2937e-01, -1.2620e-01, -1.2303e-01,  ...,  4.4282e-03,\n            4.2856e-03,  4.1431e-03],\n          [-1.3472e-01, -1.3159e-01, -1.2847e-01,  ...,  3.6654e-03,\n            3.8891e-03,  4.1128e-03],\n          ...,\n          [-1.1785e-01, -1.1355e-01, -1.0926e-01,  ...,  5.5565e-01,\n            5.6426e-01,  5.7286e-01],\n          [-1.1389e-01, -1.1012e-01, -1.0635e-01,  ...,  5.6582e-01,\n            5.7434e-01,  5.8287e-01],\n          [-1.0993e-01, -1.0668e-01, -1.0343e-01,  ...,  5.7598e-01,\n            5.8443e-01,  5.9288e-01]],\n\n         [[-4.1384e-02, -4.1273e-02, -4.1161e-02,  ...,  1.7661e-01,\n            1.8804e-01,  1.9946e-01],\n          [-3.5846e-02, -3.5782e-02, -3.5718e-02,  ...,  1.6132e-01,\n            1.7243e-01,  1.8355e-01],\n          [-3.0308e-02, -3.0291e-02, -3.0274e-02,  ...,  1.4602e-01,\n            1.5683e-01,  1.6763e-01],\n          ...,\n          [-5.1875e-01, -5.0247e-01, -4.8620e-01,  ...,  1.9693e-01,\n            2.2413e-01,  2.5134e-01],\n          [-5.2877e-01, -5.1240e-01, -4.9603e-01,  ...,  2.1592e-01,\n            2.4340e-01,  2.7088e-01],\n          [-5.3879e-01, -5.2233e-01, -5.0587e-01,  ...,  2.3490e-01,\n            2.6266e-01,  2.9041e-01]],\n\n         [[-4.6603e-02, -4.7031e-02, -4.7459e-02,  ..., -1.8268e-01,\n           -1.7618e-01, -1.6968e-01],\n          [-5.2282e-02, -5.2915e-02, -5.3548e-02,  ..., -1.9148e-01,\n           -1.8494e-01, -1.7840e-01],\n          [-5.7960e-02, -5.8798e-02, -5.9636e-02,  ..., -2.0028e-01,\n           -1.9370e-01, -1.8712e-01],\n          ...,\n          [-2.1689e-01, -2.1162e-01, -2.0636e-01,  ..., -1.7145e-01,\n           -1.6432e-01, -1.5720e-01],\n          [-2.1655e-01, -2.1104e-01, -2.0554e-01,  ..., -1.7336e-01,\n           -1.6649e-01, -1.5961e-01],\n          [-2.1621e-01, -2.1046e-01, -2.0471e-01,  ..., -1.7528e-01,\n           -1.6865e-01, -1.6203e-01]]],\n\n\n        [[[ 1.1557e-01,  1.1895e-01,  1.2233e-01,  ...,  3.0951e-01,\n            3.1249e-01,  3.1547e-01],\n          [ 1.1441e-01,  1.1773e-01,  1.2106e-01,  ...,  3.0543e-01,\n            3.0837e-01,  3.1130e-01],\n          [ 1.1326e-01,  1.1652e-01,  1.1978e-01,  ...,  3.0135e-01,\n            3.0424e-01,  3.0713e-01],\n          ...,\n          [-1.2872e-01, -1.2275e-01, -1.1678e-01,  ...,  4.4936e-02,\n            5.7155e-02,  6.9373e-02],\n          [-1.2449e-01, -1.1839e-01, -1.1229e-01,  ...,  4.5598e-02,\n            5.8245e-02,  7.0891e-02],\n          [-1.2026e-01, -1.1403e-01, -1.0780e-01,  ...,  4.6261e-02,\n            5.9335e-02,  7.2409e-02]],\n\n         [[-2.2539e-01, -2.2160e-01, -2.1781e-01,  ..., -5.0205e-02,\n           -5.1177e-02, -5.2150e-02],\n          [-2.2472e-01, -2.2102e-01, -2.1732e-01,  ..., -4.8584e-02,\n           -4.9381e-02, -5.0178e-02],\n          [-2.2404e-01, -2.2043e-01, -2.1682e-01,  ..., -4.6962e-02,\n           -4.7585e-02, -4.8207e-02],\n          ...,\n          [-1.1082e-01, -1.0222e-01, -9.3612e-02,  ..., -4.3231e-01,\n           -4.4202e-01, -4.5174e-01],\n          [-1.0687e-01, -9.8239e-02, -8.9612e-02,  ..., -4.4110e-01,\n           -4.5119e-01, -4.6127e-01],\n          [-1.0291e-01, -9.4262e-02, -8.5612e-02,  ..., -4.4989e-01,\n           -4.6035e-01, -4.7080e-01]],\n\n         [[ 7.8044e-02,  7.6095e-02,  7.4147e-02,  ...,  3.2115e-01,\n            3.2682e-01,  3.3250e-01],\n          [ 7.8310e-02,  7.6449e-02,  7.4589e-02,  ...,  3.0604e-01,\n            3.1132e-01,  3.1660e-01],\n          [ 7.8576e-02,  7.6804e-02,  7.5031e-02,  ...,  2.9094e-01,\n            2.9583e-01,  3.0071e-01],\n          ...,\n          [-5.4670e-01, -5.2547e-01, -5.0425e-01,  ..., -3.6667e-01,\n           -3.6995e-01, -3.7324e-01],\n          [-5.6512e-01, -5.4382e-01, -5.2253e-01,  ..., -3.6582e-01,\n           -3.6924e-01, -3.7267e-01],\n          [-5.8354e-01, -5.6217e-01, -5.4080e-01,  ..., -3.6497e-01,\n           -3.6853e-01, -3.7210e-01]],\n\n         ...,\n\n         [[-3.6594e-01, -3.6306e-01, -3.6019e-01,  ..., -3.3606e-01,\n           -3.2892e-01, -3.2177e-01],\n          [-3.6577e-01, -3.6297e-01, -3.6017e-01,  ..., -3.3100e-01,\n           -3.2398e-01, -3.1695e-01],\n          [-3.6561e-01, -3.6288e-01, -3.6015e-01,  ..., -3.2594e-01,\n           -3.1904e-01, -3.1214e-01],\n          ...,\n          [-4.5550e-01, -4.5823e-01, -4.6097e-01,  ..., -4.0961e-01,\n           -4.2421e-01, -4.3881e-01],\n          [-4.7381e-01, -4.7694e-01, -4.8007e-01,  ..., -4.1611e-01,\n           -4.3112e-01, -4.4613e-01],\n          [-4.9211e-01, -4.9564e-01, -4.9917e-01,  ..., -4.2260e-01,\n           -4.3802e-01, -4.5344e-01]],\n\n         [[ 1.0632e-01,  1.1084e-01,  1.1535e-01,  ..., -1.3339e-01,\n           -1.3766e-01, -1.4192e-01],\n          [ 1.0462e-01,  1.0905e-01,  1.1347e-01,  ..., -1.3538e-01,\n           -1.3965e-01, -1.4393e-01],\n          [ 1.0291e-01,  1.0726e-01,  1.1160e-01,  ..., -1.3736e-01,\n           -1.4165e-01, -1.4594e-01],\n          ...,\n          [-3.1798e-01, -3.0828e-01, -2.9859e-01,  ...,  2.0433e-01,\n            2.2372e-01,  2.4311e-01],\n          [-3.1726e-01, -3.0726e-01, -2.9726e-01,  ...,  2.1344e-01,\n            2.3308e-01,  2.5273e-01],\n          [-3.1655e-01, -3.0624e-01, -2.9594e-01,  ...,  2.2254e-01,\n            2.4244e-01,  2.6235e-01]],\n\n         [[-2.4712e-01, -2.4642e-01, -2.4572e-01,  ..., -3.9210e-01,\n           -3.9729e-01, -4.0248e-01],\n          [-2.4600e-01, -2.4543e-01, -2.4485e-01,  ..., -3.8723e-01,\n           -3.9206e-01, -3.9688e-01],\n          [-2.4488e-01, -2.4443e-01, -2.4398e-01,  ..., -3.8237e-01,\n           -3.8683e-01, -3.9128e-01],\n          ...,\n          [-1.7925e-01, -1.6604e-01, -1.5284e-01,  ...,  2.7687e-01,\n            2.8381e-01,  2.9076e-01],\n          [-1.7984e-01, -1.6596e-01, -1.5209e-01,  ...,  2.8672e-01,\n            2.9445e-01,  3.0218e-01],\n          [-1.8043e-01, -1.6589e-01, -1.5135e-01,  ...,  2.9657e-01,\n            3.0509e-01,  3.1361e-01]]],\n\n\n        [[[ 3.1684e-02,  4.7996e-02,  6.4308e-02,  ..., -7.9982e-02,\n           -6.5689e-02, -5.1396e-02],\n          [ 4.7690e-02,  6.3540e-02,  7.9391e-02,  ..., -5.9594e-02,\n           -4.5073e-02, -3.0553e-02],\n          [ 6.3695e-02,  7.9085e-02,  9.4474e-02,  ..., -3.9205e-02,\n           -2.4457e-02, -9.7089e-03],\n          ...,\n          [ 1.8625e-01,  1.9100e-01,  1.9575e-01,  ...,  5.3996e-02,\n            3.7999e-02,  2.2002e-02],\n          [ 1.9095e-01,  1.9557e-01,  2.0018e-01,  ...,  4.1414e-02,\n            2.4460e-02,  7.5056e-03],\n          [ 1.9566e-01,  2.0014e-01,  2.0462e-01,  ...,  2.8832e-02,\n            1.0920e-02, -6.9910e-03]],\n\n         [[-4.3605e-01, -4.2695e-01, -4.1786e-01,  ..., -2.1782e-01,\n           -2.0776e-01, -1.9770e-01],\n          [-4.3505e-01, -4.2613e-01, -4.1721e-01,  ..., -2.2252e-01,\n           -2.1246e-01, -2.0241e-01],\n          [-4.3405e-01, -4.2530e-01, -4.1656e-01,  ..., -2.2721e-01,\n           -2.1716e-01, -2.0711e-01],\n          ...,\n          [-4.0114e-01, -3.9007e-01, -3.7901e-01,  ..., -8.2833e-01,\n           -8.4678e-01, -8.6523e-01],\n          [-4.0042e-01, -3.8906e-01, -3.7771e-01,  ..., -8.5080e-01,\n           -8.6982e-01, -8.8885e-01],\n          [-3.9971e-01, -3.8806e-01, -3.7641e-01,  ..., -8.7327e-01,\n           -8.9287e-01, -9.1246e-01]],\n\n         [[-4.4647e-02, -3.6118e-02, -2.7589e-02,  ...,  3.5082e-01,\n            3.6005e-01,  3.6928e-01],\n          [-2.8728e-02, -2.0230e-02, -1.1733e-02,  ...,  3.3594e-01,\n            3.4442e-01,  3.5290e-01],\n          [-1.2809e-02, -4.3426e-03,  4.1238e-03,  ...,  3.2107e-01,\n            3.2879e-01,  3.3652e-01],\n          ...,\n          [ 1.1984e-01,  1.1908e-01,  1.1833e-01,  ..., -6.2317e-02,\n           -7.0117e-02, -7.7917e-02],\n          [ 1.1278e-01,  1.1233e-01,  1.1187e-01,  ..., -6.6536e-02,\n           -7.4574e-02, -8.2612e-02],\n          [ 1.0572e-01,  1.0557e-01,  1.0542e-01,  ..., -7.0755e-02,\n           -7.9030e-02, -8.7306e-02]],\n\n         ...,\n\n         [[ 2.7227e-02,  9.2364e-03, -8.7540e-03,  ..., -4.7227e-01,\n           -4.9095e-01, -5.0962e-01],\n          [ 1.2707e-02, -4.6015e-03, -2.1910e-02,  ..., -4.7999e-01,\n           -4.9924e-01, -5.1848e-01],\n          [-1.8118e-03, -1.8439e-02, -3.5067e-02,  ..., -4.8771e-01,\n           -5.0753e-01, -5.2734e-01],\n          ...,\n          [-2.3944e-01, -2.3367e-01, -2.2790e-01,  ...,  7.5214e-02,\n            9.2076e-02,  1.0894e-01],\n          [-2.5459e-01, -2.4826e-01, -2.4193e-01,  ...,  9.0976e-02,\n            1.0817e-01,  1.2536e-01],\n          [-2.6974e-01, -2.6285e-01, -2.5596e-01,  ...,  1.0674e-01,\n            1.2426e-01,  1.4179e-01]],\n\n         [[-1.1802e-01, -1.3254e-01, -1.4706e-01,  ..., -2.7417e-01,\n           -2.8118e-01, -2.8819e-01],\n          [-1.2309e-01, -1.3730e-01, -1.5151e-01,  ..., -2.7905e-01,\n           -2.8635e-01, -2.9365e-01],\n          [-1.2817e-01, -1.4207e-01, -1.5597e-01,  ..., -2.8392e-01,\n           -2.9152e-01, -2.9911e-01],\n          ...,\n          [ 1.9905e-01,  1.9411e-01,  1.8917e-01,  ..., -6.0454e-01,\n           -6.1377e-01, -6.2300e-01],\n          [ 1.9467e-01,  1.9001e-01,  1.8535e-01,  ..., -5.9138e-01,\n           -5.9990e-01, -6.0843e-01],\n          [ 1.9028e-01,  1.8590e-01,  1.8153e-01,  ..., -5.7822e-01,\n           -5.8603e-01, -5.9385e-01]],\n\n         [[-2.0711e-01, -2.0354e-01, -1.9997e-01,  ...,  2.5762e-03,\n            1.1139e-02,  1.9702e-02],\n          [-2.0188e-01, -1.9859e-01, -1.9530e-01,  ..., -2.8326e-02,\n           -2.0568e-02, -1.2810e-02],\n          [-1.9665e-01, -1.9363e-01, -1.9062e-01,  ..., -5.9227e-02,\n           -5.2275e-02, -4.5322e-02],\n          ...,\n          [-2.4087e-01, -2.4661e-01, -2.5235e-01,  ..., -2.3515e-01,\n           -2.3929e-01, -2.4344e-01],\n          [-2.5545e-01, -2.6113e-01, -2.6681e-01,  ..., -2.4326e-01,\n           -2.4771e-01, -2.5216e-01],\n          [-2.7003e-01, -2.7564e-01, -2.8126e-01,  ..., -2.5138e-01,\n           -2.5613e-01, -2.6088e-01]]],\n\n\n        ...,\n\n\n        [[[-1.0308e-01, -9.8910e-02, -9.4742e-02,  ...,  1.7255e-01,\n            1.8377e-01,  1.9499e-01],\n          [-1.0217e-01, -9.8296e-02, -9.4426e-02,  ...,  1.7171e-01,\n            1.8235e-01,  1.9300e-01],\n          [-1.0126e-01, -9.7683e-02, -9.4109e-02,  ...,  1.7087e-01,\n            1.8094e-01,  1.9101e-01],\n          ...,\n          [-4.2390e-01, -4.3242e-01, -4.4093e-01,  ...,  9.3580e-02,\n            9.5936e-02,  9.8292e-02],\n          [-4.4651e-01, -4.5448e-01, -4.6246e-01,  ...,  9.4116e-02,\n            9.6671e-02,  9.9225e-02],\n          [-4.6911e-01, -4.7655e-01, -4.8398e-01,  ...,  9.4651e-02,\n            9.7405e-02,  1.0016e-01]],\n\n         [[-3.7604e-01, -3.6928e-01, -3.6252e-01,  ..., -3.7202e-01,\n           -3.8051e-01, -3.8901e-01],\n          [-3.6878e-01, -3.6210e-01, -3.5542e-01,  ..., -3.6848e-01,\n           -3.7671e-01, -3.8494e-01],\n          [-3.6151e-01, -3.5492e-01, -3.4833e-01,  ..., -3.6495e-01,\n           -3.7291e-01, -3.8087e-01],\n          ...,\n          [-5.5406e-01, -5.4594e-01, -5.3781e-01,  ...,  3.6952e-01,\n            3.7555e-01,  3.8158e-01],\n          [-5.5824e-01, -5.5010e-01, -5.4196e-01,  ...,  3.8593e-01,\n            3.9218e-01,  3.9843e-01],\n          [-5.6241e-01, -5.5425e-01, -5.4610e-01,  ...,  4.0234e-01,\n            4.0881e-01,  4.1528e-01]],\n\n         [[ 2.2276e-01,  2.2087e-01,  2.1897e-01,  ..., -9.1825e-03,\n           -7.0213e-03, -4.8601e-03],\n          [ 2.1785e-01,  2.1601e-01,  2.1418e-01,  ..., -6.8727e-03,\n           -4.9545e-03, -3.0362e-03],\n          [ 2.1293e-01,  2.1116e-01,  2.0939e-01,  ..., -4.5628e-03,\n           -2.8876e-03, -1.2124e-03],\n          ...,\n          [-1.5299e-02, -3.5363e-04,  1.4592e-02,  ...,  2.6261e-01,\n            2.5561e-01,  2.4862e-01],\n          [-1.9608e-02, -4.9875e-03,  9.6333e-03,  ...,  2.7260e-01,\n            2.6576e-01,  2.5892e-01],\n          [-2.3918e-02, -9.6213e-03,  4.6750e-03,  ...,  2.8259e-01,\n            2.7591e-01,  2.6923e-01]],\n\n         ...,\n\n         [[ 9.3476e-02,  6.9841e-02,  4.6206e-02,  ..., -3.6560e-01,\n           -3.6287e-01, -3.6014e-01],\n          [ 9.6597e-02,  7.3491e-02,  5.0385e-02,  ..., -3.4862e-01,\n           -3.4544e-01, -3.4225e-01],\n          [ 9.9719e-02,  7.7141e-02,  5.4563e-02,  ..., -3.3165e-01,\n           -3.2800e-01, -3.2436e-01],\n          ...,\n          [-4.1040e-02, -2.2689e-02, -4.3386e-03,  ..., -1.0880e-01,\n           -1.0965e-01, -1.1050e-01],\n          [-5.0205e-02, -3.1770e-02, -1.3335e-02,  ..., -1.2396e-01,\n           -1.2533e-01, -1.2671e-01],\n          [-5.9371e-02, -4.0851e-02, -2.2332e-02,  ..., -1.3912e-01,\n           -1.4102e-01, -1.4292e-01]],\n\n         [[-2.2028e-01, -2.1416e-01, -2.0805e-01,  ..., -3.4293e-01,\n           -3.4703e-01, -3.5113e-01],\n          [-2.2466e-01, -2.1836e-01, -2.1207e-01,  ..., -3.3994e-01,\n           -3.4336e-01, -3.4677e-01],\n          [-2.2905e-01, -2.2256e-01, -2.1608e-01,  ..., -3.3696e-01,\n           -3.3968e-01, -3.4240e-01],\n          ...,\n          [ 9.2271e-01,  9.0199e-01,  8.8127e-01,  ...,  1.8859e-01,\n            1.9396e-01,  1.9934e-01],\n          [ 9.4236e-01,  9.2135e-01,  9.0035e-01,  ...,  1.9552e-01,\n            2.0075e-01,  2.0599e-01],\n          [ 9.6201e-01,  9.4072e-01,  9.1943e-01,  ...,  2.0244e-01,\n            2.0754e-01,  2.1264e-01]],\n\n         [[-4.8980e-02, -5.4787e-02, -6.0594e-02,  ..., -1.6235e-01,\n           -1.6057e-01, -1.5879e-01],\n          [-5.5838e-02, -6.1325e-02, -6.6811e-02,  ..., -1.5007e-01,\n           -1.4811e-01, -1.4616e-01],\n          [-6.2696e-02, -6.7862e-02, -7.3029e-02,  ..., -1.3780e-01,\n           -1.3566e-01, -1.3353e-01],\n          ...,\n          [ 5.6161e-01,  5.2351e-01,  4.8540e-01,  ...,  5.6375e-02,\n            6.0456e-02,  6.4537e-02],\n          [ 5.6049e-01,  5.2227e-01,  4.8404e-01,  ...,  5.2580e-02,\n            5.6894e-02,  6.1209e-02],\n          [ 5.5938e-01,  5.2103e-01,  4.8268e-01,  ...,  4.8785e-02,\n            5.3333e-02,  5.7881e-02]]],\n\n\n        [[[-1.3791e-01, -1.4008e-01, -1.4226e-01,  ...,  3.7345e-02,\n            3.7568e-02,  3.7791e-02],\n          [-1.4987e-01, -1.5166e-01, -1.5346e-01,  ...,  4.0648e-02,\n            4.0881e-02,  4.1114e-02],\n          [-1.6183e-01, -1.6325e-01, -1.6466e-01,  ...,  4.3951e-02,\n            4.4194e-02,  4.4436e-02],\n          ...,\n          [ 1.0085e-01,  1.0626e-01,  1.1166e-01,  ...,  1.0747e-03,\n           -4.5172e-03, -1.0109e-02],\n          [ 1.0406e-01,  1.0941e-01,  1.1477e-01,  ...,  5.3332e-03,\n           -6.1145e-04, -6.5561e-03],\n          [ 1.0726e-01,  1.1257e-01,  1.1789e-01,  ...,  9.5917e-03,\n            3.2943e-03, -3.0030e-03]],\n\n         [[-1.3505e-01, -1.3056e-01, -1.2608e-01,  ...,  4.2080e-02,\n            4.2583e-02,  4.3085e-02],\n          [-1.2052e-01, -1.1652e-01, -1.1251e-01,  ...,  3.9903e-02,\n            4.0442e-02,  4.0981e-02],\n          [-1.0600e-01, -1.0247e-01, -9.8944e-02,  ...,  3.7727e-02,\n            3.8302e-02,  3.8877e-02],\n          ...,\n          [-3.3790e-01, -3.4072e-01, -3.4354e-01,  ...,  6.4502e-02,\n            7.0365e-02,  7.6227e-02],\n          [-3.3937e-01, -3.4205e-01, -3.4472e-01,  ...,  5.2589e-02,\n            5.8377e-02,  6.4165e-02],\n          [-3.4085e-01, -3.4337e-01, -3.4590e-01,  ...,  4.0675e-02,\n            4.6389e-02,  5.2103e-02]],\n\n         [[ 2.6694e-02,  4.1723e-02,  5.6752e-02,  ...,  4.6002e-02,\n            4.5542e-02,  4.5082e-02],\n          [ 3.2443e-02,  4.7051e-02,  6.1659e-02,  ...,  4.3274e-02,\n            4.2732e-02,  4.2190e-02],\n          [ 3.8193e-02,  5.2379e-02,  6.6566e-02,  ...,  4.0545e-02,\n            3.9922e-02,  3.9298e-02],\n          ...,\n          [ 4.2094e-01,  4.1443e-01,  4.0793e-01,  ..., -9.1843e-02,\n           -8.8228e-02, -8.4614e-02],\n          [ 4.2206e-01,  4.1556e-01,  4.0905e-01,  ..., -8.3947e-02,\n           -7.9817e-02, -7.5686e-02],\n          [ 4.2319e-01,  4.1668e-01,  4.1018e-01,  ..., -7.6051e-02,\n           -7.1405e-02, -6.6759e-02]],\n\n         ...,\n\n         [[-3.0951e-01, -3.0011e-01, -2.9070e-01,  ..., -1.4832e-02,\n           -1.3828e-02, -1.2823e-02],\n          [-3.0983e-01, -3.0103e-01, -2.9223e-01,  ..., -1.3409e-02,\n           -1.2438e-02, -1.1468e-02],\n          [-3.1014e-01, -3.0196e-01, -2.9377e-01,  ..., -1.1985e-02,\n           -1.1049e-02, -1.0113e-02],\n          ...,\n          [-3.3019e-01, -3.3559e-01, -3.4099e-01,  ..., -2.8195e-02,\n           -2.9810e-02, -3.1425e-02],\n          [-3.2552e-01, -3.3107e-01, -3.3662e-01,  ..., -2.3010e-02,\n           -2.4479e-02, -2.5949e-02],\n          [-3.2086e-01, -3.2655e-01, -3.3225e-01,  ..., -1.7825e-02,\n           -1.9149e-02, -2.0473e-02]],\n\n         [[ 4.2823e-02,  2.7633e-02,  1.2443e-02,  ..., -1.6569e-03,\n           -2.3618e-03, -3.0667e-03],\n          [ 4.8340e-02,  3.3805e-02,  1.9270e-02,  ..., -3.3848e-03,\n           -4.2639e-03, -5.1429e-03],\n          [ 5.3856e-02,  3.9977e-02,  2.6098e-02,  ..., -5.1127e-03,\n           -6.1659e-03, -7.2191e-03],\n          ...,\n          [ 1.8121e-01,  1.7587e-01,  1.7053e-01,  ..., -1.4640e-02,\n           -7.0754e-03,  4.8882e-04],\n          [ 1.7956e-01,  1.7424e-01,  1.6893e-01,  ..., -1.5764e-02,\n           -7.8203e-03,  1.2301e-04],\n          [ 1.7790e-01,  1.7262e-01,  1.6733e-01,  ..., -1.6888e-02,\n           -8.5653e-03, -2.4280e-04]],\n\n         [[ 2.5071e-01,  2.3312e-01,  2.1554e-01,  ..., -1.4750e-01,\n           -1.5249e-01, -1.5748e-01],\n          [ 2.3990e-01,  2.2227e-01,  2.0465e-01,  ..., -1.4228e-01,\n           -1.4722e-01, -1.5216e-01],\n          [ 2.2909e-01,  2.1142e-01,  1.9375e-01,  ..., -1.3705e-01,\n           -1.4195e-01, -1.4684e-01],\n          ...,\n          [-2.5360e-01, -2.5013e-01, -2.4667e-01,  ..., -1.3085e-01,\n           -1.3613e-01, -1.4141e-01],\n          [-2.5476e-01, -2.5161e-01, -2.4846e-01,  ..., -1.3514e-01,\n           -1.4076e-01, -1.4637e-01],\n          [-2.5592e-01, -2.5308e-01, -2.5024e-01,  ..., -1.3944e-01,\n           -1.4538e-01, -1.5133e-01]]],\n\n\n        [[[-1.4620e-01, -1.4281e-01, -1.3943e-01,  ..., -2.6974e-01,\n           -2.7943e-01, -2.8912e-01],\n          [-1.3951e-01, -1.3645e-01, -1.3338e-01,  ..., -2.8979e-01,\n           -2.9945e-01, -3.0911e-01],\n          [-1.3282e-01, -1.3008e-01, -1.2734e-01,  ..., -3.0983e-01,\n           -3.1946e-01, -3.2910e-01],\n          ...,\n          [ 3.1417e-01,  3.0856e-01,  3.0295e-01,  ...,  1.7162e-01,\n            1.6898e-01,  1.6633e-01],\n          [ 3.1175e-01,  3.0625e-01,  3.0075e-01,  ...,  1.7449e-01,\n            1.7138e-01,  1.6828e-01],\n          [ 3.0933e-01,  3.0394e-01,  2.9855e-01,  ...,  1.7736e-01,\n            1.7379e-01,  1.7023e-01]],\n\n         [[ 3.2155e-01,  3.0912e-01,  2.9670e-01,  ...,  2.5753e-01,\n            2.6651e-01,  2.7549e-01],\n          [ 3.0369e-01,  2.9179e-01,  2.7989e-01,  ...,  2.4398e-01,\n            2.5239e-01,  2.6080e-01],\n          [ 2.8583e-01,  2.7445e-01,  2.6307e-01,  ...,  2.3044e-01,\n            2.3828e-01,  2.4612e-01],\n          ...,\n          [-1.0134e-01, -1.1051e-01, -1.1968e-01,  ..., -2.8103e-01,\n           -2.6667e-01, -2.5232e-01],\n          [-9.2815e-02, -1.0230e-01, -1.1178e-01,  ..., -2.8927e-01,\n           -2.7532e-01, -2.6137e-01],\n          [-8.4286e-02, -9.4085e-02, -1.0388e-01,  ..., -2.9751e-01,\n           -2.8396e-01, -2.7041e-01]],\n\n         [[ 5.5090e-04,  9.6235e-03,  1.8696e-02,  ...,  1.6502e-01,\n            1.6555e-01,  1.6608e-01],\n          [-5.0630e-03,  3.9855e-03,  1.3034e-02,  ...,  1.7547e-01,\n            1.7595e-01,  1.7643e-01],\n          [-1.0677e-02, -1.6525e-03,  7.3720e-03,  ...,  1.8591e-01,\n            1.8635e-01,  1.8679e-01],\n          ...,\n          [ 2.6118e-01,  2.6198e-01,  2.6277e-01,  ..., -2.6871e-01,\n           -2.8390e-01, -2.9910e-01],\n          [ 2.6824e-01,  2.6920e-01,  2.7015e-01,  ..., -2.7317e-01,\n           -2.8822e-01, -3.0328e-01],\n          [ 2.7531e-01,  2.7641e-01,  2.7752e-01,  ..., -2.7762e-01,\n           -2.9254e-01, -3.0746e-01]],\n\n         ...,\n\n         [[ 2.9935e-03, -9.1689e-03, -2.1331e-02,  ..., -3.5198e-01,\n           -3.6031e-01, -3.6864e-01],\n          [-7.3889e-03, -1.9340e-02, -3.1291e-02,  ..., -3.5986e-01,\n           -3.6817e-01, -3.7648e-01],\n          [-1.7771e-02, -2.9511e-02, -4.1251e-02,  ..., -3.6774e-01,\n           -3.7603e-01, -3.8431e-01],\n          ...,\n          [-1.7431e-01, -1.7167e-01, -1.6904e-01,  ..., -6.6896e-02,\n           -5.6111e-02, -4.5326e-02],\n          [-1.7404e-01, -1.7176e-01, -1.6948e-01,  ..., -7.2031e-02,\n           -6.0947e-02, -4.9863e-02],\n          [-1.7378e-01, -1.7185e-01, -1.6992e-01,  ..., -7.7165e-02,\n           -6.5783e-02, -5.4400e-02]],\n\n         [[-1.8649e-01, -1.9131e-01, -1.9613e-01,  ...,  3.6786e-01,\n            3.7784e-01,  3.8782e-01],\n          [-1.7348e-01, -1.7807e-01, -1.8267e-01,  ...,  3.5652e-01,\n            3.6577e-01,  3.7501e-01],\n          [-1.6048e-01, -1.6484e-01, -1.6920e-01,  ...,  3.4518e-01,\n            3.5369e-01,  3.6221e-01],\n          ...,\n          [ 2.8335e-01,  2.8590e-01,  2.8846e-01,  ...,  1.4978e-01,\n            1.6595e-01,  1.8212e-01],\n          [ 2.8927e-01,  2.9202e-01,  2.9477e-01,  ...,  1.4001e-01,\n            1.5630e-01,  1.7258e-01],\n          [ 2.9518e-01,  2.9813e-01,  3.0109e-01,  ...,  1.3024e-01,\n            1.4664e-01,  1.6304e-01]],\n\n         [[-3.2323e-01, -3.1597e-01, -3.0871e-01,  ..., -1.8744e-01,\n           -1.9595e-01, -2.0445e-01],\n          [-3.2050e-01, -3.1331e-01, -3.0612e-01,  ..., -1.8313e-01,\n           -1.9129e-01, -1.9946e-01],\n          [-3.1777e-01, -3.1065e-01, -3.0353e-01,  ..., -1.7881e-01,\n           -1.8664e-01, -1.9448e-01],\n          ...,\n          [-4.8707e-01, -4.9528e-01, -5.0350e-01,  ..., -2.9803e-01,\n           -2.9591e-01, -2.9379e-01],\n          [-5.0456e-01, -5.1266e-01, -5.2076e-01,  ..., -2.9765e-01,\n           -2.9534e-01, -2.9303e-01],\n          [-5.2205e-01, -5.3004e-01, -5.3802e-01,  ..., -2.9726e-01,\n           -2.9477e-01, -2.9228e-01]]]], grad_fn=<UpsampleBilinear2DBackward0>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "model = PSPNet(n_classes=20)\n",
    "input = next(iter(train_dataloader))[0]\n",
    "pred = model(input)\n",
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T17:24:21.700576300Z",
     "start_time": "2023-08-27T17:24:19.394520800Z"
    }
   },
   "id": "85adb0e8ec74b8aa"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\nPSPNet                                             [16, 20, 256, 256]        --\n├─CustomResNet101: 1-1                             [16, 2048, 8, 8]          --\n│    └─ResNet: 2-1                                 --                        2,049,000\n│    │    └─Conv2d: 3-1                            [16, 64, 128, 128]        9,408\n│    │    └─BatchNorm2d: 3-2                       [16, 64, 128, 128]        128\n│    │    └─ReLU: 3-3                              [16, 64, 128, 128]        --\n│    │    └─MaxPool2d: 3-4                         [16, 64, 64, 64]          --\n│    │    └─Sequential: 3-5                        [16, 256, 64, 64]         215,808\n│    │    └─Sequential: 3-6                        [16, 512, 32, 32]         1,219,584\n│    │    └─Sequential: 3-7                        [16, 1024, 16, 16]        26,090,496\n│    │    └─Sequential: 3-8                        [16, 2048, 8, 8]          14,964,736\n├─PyramidPooling: 1-2                              [16, 4096, 8, 8]          --\n│    └─AdaptiveAvgPool2d: 2-2                      [16, 2048, 6, 6]          --\n│    └─Conv2d: 2-3                                 [16, 512, 6, 6]           1,049,088\n│    └─AdaptiveAvgPool2d: 2-4                      [16, 2048, 3, 3]          --\n│    └─Conv2d: 2-5                                 [16, 512, 3, 3]           (recursive)\n│    └─AdaptiveAvgPool2d: 2-6                      [16, 2048, 2, 2]          --\n│    └─Conv2d: 2-7                                 [16, 512, 2, 2]           (recursive)\n│    └─AdaptiveAvgPool2d: 2-8                      [16, 2048, 1, 1]          --\n│    └─Conv2d: 2-9                                 [16, 512, 1, 1]           (recursive)\n├─DecodePSPFeature: 1-3                            [16, 20, 256, 256]        --\n│    └─conv2DBatchNorm: 2-10                       [16, 64, 8, 8]            --\n│    │    └─Conv2d: 3-9                            [16, 64, 8, 8]            2,359,296\n│    │    └─BatchNorm2d: 3-10                      [16, 64, 8, 8]            128\n│    │    └─ReLU: 3-11                             [16, 64, 8, 8]            --\n│    └─Dropout2d: 2-11                             [16, 64, 8, 8]            --\n│    └─Conv2d: 2-12                                [16, 20, 8, 8]            1,300\n====================================================================================================\nTotal params: 47,958,972\nTrainable params: 47,958,972\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 166.25\n====================================================================================================\nInput size (MB): 12.58\nForward/backward pass size (MB): 5431.92\nParams size (MB): 183.64\nEstimated Total Size (MB): 5628.14\n===================================================================================================="
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = PSPNet(n_classes=20)\n",
    "batch_size = 16\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(batch_size, 3, 256, 256),\n",
    "    col_names=[\"output_size\", \"num_params\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T17:24:07.632780Z",
     "start_time": "2023-08-27T17:24:05.916257500Z"
    }
   },
   "id": "f229e4c5104c9089"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class PSPLoss(nn.Module):\n",
    "    def __init__(self, aux_weight=0.4):\n",
    "        super().__init__()\n",
    "        self.aux_weight = aux_weight\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = F.cross_entropy(outputs, targets, reduction='mean')\n",
    "        #loss_aux = F.cross_entropy(outputs[1], targets, reduction='mean')\n",
    "\n",
    "        return loss #+ self.aux_weight * loss_aux\n",
    "\n",
    "criterion = PSPLoss(aux_weight=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T15:02:01.057224300Z",
     "start_time": "2023-08-27T15:02:01.032167100Z"
    }
   },
   "id": "d87426074070be30"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "loss_fn = PSPLoss()\n",
    "LEARNING_RATE = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T15:02:02.940007200Z",
     "start_time": "2023-08-27T15:02:02.906926600Z"
    }
   },
   "id": "979957e7a93fa2d2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "## For the model training loop.\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cpu'\n",
    "else: DEVICE = 'cpu'\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, device=DEVICE):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        predictions = model(data)\n",
    "        targets = torch.argmax(targets, dim=1)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        train_loss += loss.detach().cpu().numpy() * BATCH_SIZE\n",
    "\n",
    "    train_loss = train_loss / (BATCH_SIZE * len(train_dataloader))\n",
    "    return train_loss\n",
    "\n",
    "## For the model validation loop.\n",
    "def valid_fn(loader, model, loss_fn, device=DEVICE):\n",
    "    model.eval()\n",
    "    valid_loss = 0.\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(loop):\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            predictions = model(data)\n",
    "            targets = torch.argmax(targets, dim=1)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            valid_loss += loss * BATCH_SIZE\n",
    "\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        valid_loss = valid_loss / (BATCH_SIZE * len(test_dataloader))\n",
    "    return valid_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T17:26:34.039180400Z",
     "start_time": "2023-08-27T17:26:34.003617300Z"
    }
   },
   "id": "6cc5bc6fb5b9b52d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [18:08<00:00, 11.84s/it, loss=1.07]\n",
      "100%|██████████| 91/91 [05:52<00:00,  3.87s/it, loss=1.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model saved!\n",
      "Train Loss: 1.2260723995125813,  Valid Loss: 1.0915895700454712\n",
      "-------------\n",
      "Epoch 1/1\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [17:39<00:00, 11.52s/it, loss=0.895]\n",
      "100%|██████████| 91/91 [05:43<00:00,  3.77s/it, loss=0.859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model saved!\n",
      "Train Loss: 0.9901133944158969,  Valid Loss: 0.8448228240013123\n"
     ]
    }
   ],
   "source": [
    "## For the train & validation loop.\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "## DeepLabv3 model\n",
    "model.to(device=DEVICE)\n",
    "\n",
    "best_loss = 100\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('-------------')\n",
    "    print('Epoch {}/{}'.format(epoch+1, NUM_EPOCHS))\n",
    "    print('-------------')\n",
    "\n",
    "    train_loss = train_fn(train_dataloader, model, optimizer, loss_fn, DEVICE)\n",
    "    valid_loss = valid_fn(test_dataloader, model, loss_fn, DEVICE)\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, \"./checkpoint.pth\")\n",
    "        print('best model saved!')\n",
    "        best_loss = valid_loss\n",
    "\n",
    "    print(f'Train Loss: {train_loss},  Valid Loss: {valid_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T17:26:39.423230Z",
     "start_time": "2023-08-27T17:26:38.850872Z"
    }
   },
   "id": "f0b181263b3000d3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a678a26394c0e0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
