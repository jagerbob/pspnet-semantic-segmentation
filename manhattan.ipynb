{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:03.917256100Z",
     "start_time": "2023-08-27T11:44:03.897086300Z"
    }
   },
   "id": "40f5e12d90480ef"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data\\VOCtrainval_11-May-2012.tar to ./data\n",
      "Using downloaded and verified file: ./data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data\\VOCtrainval_11-May-2012.tar to ./data\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                      year=\"2012\",\n",
    "                                      image_set=\"train\",\n",
    "                                      download=\"true\",\n",
    "                                      transform=data_transform,\n",
    "                                      target_transform=data_transform)\n",
    "\n",
    "test_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                     year=\"2012\",\n",
    "                                     image_set=\"val\",\n",
    "                                     download=\"true\",\n",
    "                                     transform=data_transform,\n",
    "                                     target_transform=data_transform)\n",
    "\n",
    "viz_data = datasets.VOCSegmentation(root=\"./data\", year=\"2012\", image_set=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:48.499383500Z",
     "start_time": "2023-08-27T11:44:05.459771800Z"
    }
   },
   "id": "13d9279b6c994102"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader: 92 * 16 images\n",
      "test_dataloader: 91 * 16 images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"train_dataloader: {len(train_dataloader)} * {BATCH_SIZE} images\")\n",
    "print(f\"test_dataloader: {len(test_dataloader)} * {BATCH_SIZE} images\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:51.658601200Z",
     "start_time": "2023-08-27T11:44:51.638332600Z"
    }
   },
   "id": "43b89a384fa7337a"
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        auxiliary_x = self.resnet.layer3(x) # res4b22\n",
    "        x = self.resnet.layer4(auxiliary_x) # res5c\n",
    "\n",
    "        return x, auxiliary_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:46:54.906977300Z",
     "start_time": "2023-08-27T13:46:54.873900100Z"
    }
   },
   "id": "337f90049382bd35"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, input_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.pooling_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(output_size=p),\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=int(in_channels/len(pool_sizes)), kernel_size=1)\n",
    "            )\n",
    "            for p in pool_sizes\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [x]\n",
    "        for pool_layer in self.pooling_layers:\n",
    "            layer_output = pool_layer(x)\n",
    "            outputs.append(F.interpolate(layer_output, size=self.input_size, mode='bilinear', align_corners=True))\n",
    "\n",
    "        return torch.cat(outputs, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:42:17.823577800Z",
     "start_time": "2023-08-27T13:42:17.791598Z"
    }
   },
   "id": "e2319b0d8297d462"
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = CustomResNet50()\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1], input_size=(8, 8))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_output, encoder_auxiliary_output = self.encoder(x)\n",
    "        pyramid_output = self.pyramid_pooling(encoder_output)\n",
    "        return pyramid_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:49:04.564839300Z",
     "start_time": "2023-08-27T13:49:04.539756400Z"
    }
   },
   "id": "6e7e950f41abcc56"
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 3, 256, 256])"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PSPNet(n_classes=4)\n",
    "input = next(iter(train_dataloader))[0]\n",
    "pred = model(input)\n",
    "input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:51:50.216832300Z",
     "start_time": "2023-08-27T13:51:48.604626800Z"
    }
   },
   "id": "85adb0e8ec74b8aa"
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [CustomResNet50: 1, Conv2d: 3, BatchNorm2d: 3, ReLU: 3, MaxPool2d: 3, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:295\u001B[0m, in \u001B[0;36mforward_pass\u001B[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001B[0m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m--> 295\u001B[0m     _ \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1538\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n",
      "Cell \u001B[1;32mIn[225], line 9\u001B[0m, in \u001B[0;36mPSPNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      8\u001B[0m encoder_output, encoder_auxiliary_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(x)\n\u001B[1;32m----> 9\u001B[0m pyramid_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyramid_pooling\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pyramid_output\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1538\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n",
      "Cell \u001B[1;32mIn[206], line 19\u001B[0m, in \u001B[0;36mPyramidPooling.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pool_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling_layers:\n\u001B[1;32m---> 19\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mpool_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     outputs\u001B[38;5;241m.\u001B[39mappend(F\u001B[38;5;241m.\u001B[39minterpolate(layer_output, size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_size, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m'\u001B[39m, align_corners\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[227], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m PSPNet(n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      4\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[1;32m----> 6\u001B[0m \u001B[43msummary\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcol_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_size\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnum_params\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:223\u001B[0m, in \u001B[0;36msummary\u001B[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m validate_user_params(\n\u001B[0;32m    217\u001B[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001B[0;32m    218\u001B[0m )\n\u001B[0;32m    220\u001B[0m x, correct_input_size \u001B[38;5;241m=\u001B[39m process_input(\n\u001B[0;32m    221\u001B[0m     input_data, input_size, batch_dim, device, dtypes\n\u001B[0;32m    222\u001B[0m )\n\u001B[1;32m--> 223\u001B[0m summary_list \u001B[38;5;241m=\u001B[39m \u001B[43mforward_pass\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_forward_pass\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    226\u001B[0m formatting \u001B[38;5;241m=\u001B[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001B[0;32m    227\u001B[0m results \u001B[38;5;241m=\u001B[39m ModelStatistics(\n\u001B[0;32m    228\u001B[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001B[0;32m    229\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchinfo\\torchinfo.py:304\u001B[0m, in \u001B[0;36mforward_pass\u001B[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    303\u001B[0m     executed_layers \u001B[38;5;241m=\u001B[39m [layer \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m summary_list \u001B[38;5;28;01mif\u001B[39;00m layer\u001B[38;5;241m.\u001B[39mexecuted]\n\u001B[1;32m--> 304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuted layers up to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexecuted_layers\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [CustomResNet50: 1, Conv2d: 3, BatchNorm2d: 3, ReLU: 3, MaxPool2d: 3, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Sequential: 3, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, Sequential: 5, Conv2d: 6, BatchNorm2d: 6, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Bottleneck: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5, Conv2d: 5, BatchNorm2d: 5, ReLU: 5]"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = PSPNet(n_classes=4)\n",
    "batch_size = 16\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(batch_size, 3, 256, 256),\n",
    "    col_names=[\"output_size\", \"num_params\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:51:18.662849400Z",
     "start_time": "2023-08-27T13:51:17.818643600Z"
    }
   },
   "id": "f229e4c5104c9089"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
