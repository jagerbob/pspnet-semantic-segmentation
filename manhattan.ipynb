{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:03.917256100Z",
     "start_time": "2023-08-27T11:44:03.897086300Z"
    }
   },
   "id": "40f5e12d90480ef"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data\\VOCtrainval_11-May-2012.tar to ./data\n",
      "Using downloaded and verified file: ./data\\VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data\\VOCtrainval_11-May-2012.tar to ./data\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                      year=\"2012\",\n",
    "                                      image_set=\"train\",\n",
    "                                      download=\"true\",\n",
    "                                      transform=data_transform,\n",
    "                                      target_transform=data_transform)\n",
    "\n",
    "test_data = datasets.VOCSegmentation(root=\"./data\",\n",
    "                                     year=\"2012\",\n",
    "                                     image_set=\"val\",\n",
    "                                     download=\"true\",\n",
    "                                     transform=data_transform,\n",
    "                                     target_transform=data_transform)\n",
    "\n",
    "viz_data = datasets.VOCSegmentation(root=\"./data\", year=\"2012\", image_set=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:48.499383500Z",
     "start_time": "2023-08-27T11:44:05.459771800Z"
    }
   },
   "id": "13d9279b6c994102"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader: 92 * 16 images\n",
      "test_dataloader: 91 * 16 images\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"train_dataloader: {len(train_dataloader)} * {BATCH_SIZE} images\")\n",
    "print(f\"test_dataloader: {len(test_dataloader)} * {BATCH_SIZE} images\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T11:44:51.658601200Z",
     "start_time": "2023-08-27T11:44:51.638332600Z"
    }
   },
   "id": "43b89a384fa7337a"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class CustomResNet101(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet101(weights=torchvision.models.ResNet101_Weights.DEFAULT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        auxiliary_x = self.resnet.layer3(x) # res4b22\n",
    "        x = self.resnet.layer4(auxiliary_x) # res5c\n",
    "\n",
    "        return x, auxiliary_x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:42:21.677593400Z",
     "start_time": "2023-08-27T13:42:21.645932700Z"
    }
   },
   "id": "337f90049382bd35"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, input_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.pooling_layers = [\n",
    "            nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(output_size=p),\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=int(in_channels/len(pool_sizes)), kernel_size=1)\n",
    "            )\n",
    "            for p in pool_sizes\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [x]\n",
    "        for pool_layer in self.pooling_layers:\n",
    "            layer_output = pool_layer(x)\n",
    "            outputs.append(F.interpolate(layer_output, size=self.input_size, mode='bilinear', align_corners=True))\n",
    "\n",
    "        return torch.cat(outputs, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:42:17.823577800Z",
     "start_time": "2023-08-27T13:42:17.791598Z"
    }
   },
   "id": "e2319b0d8297d462"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = CustomResNet101()\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1], input_size=(8, 8))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_output, encoder_auxiliary_output = self.encoder(x)\n",
    "        pyramid_output = self.pyramid_pooling(encoder_output)\n",
    "        return pyramid_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:42:10.681188300Z",
     "start_time": "2023-08-27T13:42:10.651360100Z"
    }
   },
   "id": "6e7e950f41abcc56"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 3, 256, 256])"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PSPNet(n_classes=4)\n",
    "input = next(iter(train_dataloader))[0]\n",
    "pred = model(input)\n",
    "input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:42:34.549297600Z",
     "start_time": "2023-08-27T13:42:31.931163500Z"
    }
   },
   "id": "85adb0e8ec74b8aa"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\nPSPNet                                             [16, 4096, 8, 8]          185,096\n├─FeatureExtractor2: 1-1                           [16, 2048, 8, 8]          --\n│    └─ResNet: 2-1                                 --                        2,049,000\n│    │    └─Conv2d: 3-1                            [16, 64, 128, 128]        9,408\n│    │    └─BatchNorm2d: 3-2                       [16, 64, 128, 128]        128\n│    │    └─ReLU: 3-3                              [16, 64, 128, 128]        --\n│    │    └─MaxPool2d: 3-4                         [16, 64, 64, 64]          --\n│    │    └─Sequential: 3-5                        [16, 256, 64, 64]         215,808\n│    │    └─Sequential: 3-6                        [16, 512, 32, 32]         1,219,584\n│    │    └─Sequential: 3-7                        [16, 1024, 16, 16]        26,090,496\n│    │    └─Sequential: 3-8                        [16, 2048, 8, 8]          14,964,736\n├─PyramidPooling: 1-2                              [16, 4096, 8, 8]          --\n│    └─AdaptiveAvgPool2d: 2-2                      [16, 2048, 6, 6]          --\n│    └─conv2DBatchNorm: 2-3                        [16, 512, 6, 6]           --\n│    │    └─Conv2d: 3-9                            [16, 512, 6, 6]           1,048,576\n│    │    └─BatchNorm2d: 3-10                      [16, 512, 6, 6]           1,024\n│    │    └─ReLU: 3-11                             [16, 512, 6, 6]           --\n│    └─AdaptiveAvgPool2d: 2-4                      [16, 2048, 3, 3]          --\n│    └─conv2DBatchNorm: 2-5                        [16, 512, 3, 3]           --\n│    │    └─Conv2d: 3-12                           [16, 512, 3, 3]           1,048,576\n│    │    └─BatchNorm2d: 3-13                      [16, 512, 3, 3]           1,024\n│    │    └─ReLU: 3-14                             [16, 512, 3, 3]           --\n│    └─AdaptiveAvgPool2d: 2-6                      [16, 2048, 2, 2]          --\n│    └─conv2DBatchNorm: 2-7                        [16, 512, 2, 2]           --\n│    │    └─Conv2d: 3-15                           [16, 512, 2, 2]           1,048,576\n│    │    └─BatchNorm2d: 3-16                      [16, 512, 2, 2]           1,024\n│    │    └─ReLU: 3-17                             [16, 512, 2, 2]           --\n│    └─AdaptiveAvgPool2d: 2-8                      [16, 2048, 1, 1]          --\n│    └─conv2DBatchNorm: 2-9                        [16, 512, 1, 1]           --\n│    │    └─Conv2d: 3-18                           [16, 512, 1, 1]           1,048,576\n│    │    └─BatchNorm2d: 3-19                      [16, 512, 1, 1]           1,024\n│    │    └─ReLU: 3-20                             [16, 512, 1, 1]           --\n====================================================================================================\nTotal params: 48,932,656\nTrainable params: 48,932,656\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 163.83\n====================================================================================================\nInput size (MB): 12.58\nForward/backward pass size (MB): 5433.98\nParams size (MB): 186.79\nEstimated Total Size (MB): 5633.36\n===================================================================================================="
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PSPNet(n_classes=4)\n",
    "batch_size = 16\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(batch_size, 3, 256, 256),\n",
    "    col_names=[\"output_size\", \"num_params\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T13:16:30.640269800Z",
     "start_time": "2023-08-27T13:16:29.879179400Z"
    }
   },
   "id": "f229e4c5104c9089"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
